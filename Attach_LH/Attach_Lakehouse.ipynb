{"cells":[{"cell_type":"code","source":["# one off operation\n","!pip install -q duckdb"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"f7f4343b-4407-4443-8479-de0b827c2d23","normalized_state":"finished","queued_time":"2024-10-26T05:32:06.0907653Z","session_start_time":"2024-10-26T05:32:06.4756843Z","execution_start_time":"2024-10-26T05:32:18.1995999Z","execution_finish_time":"2024-10-26T05:32:26.8261434Z","parent_msg_id":"e3a0e4b6-50db-43c3-845c-95c5f975bb66"},"text/plain":"StatementMeta(, f7f4343b-4407-4443-8479-de0b827c2d23, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"faf1728b"},{"cell_type":"markdown","source":["Register an App if running outside Fabric to get a token\n","https://fivetran.com/docs/destinations/onelake/setup-guide"],"metadata":{},"id":"9684c385"},{"cell_type":"code","source":["import duckdb\n","def attach_lakehouse(workspace,LH):\n","    ########## get token\n","    try:\n","      token = notebookutils.credentials.getToken('storage')\n","    except:\n","        !pip install -q azure-identity\n","        from   azure.identity   import ClientSecretCredential\n","        import configparser\n","        config = configparser.ConfigParser()\n","        config.read(\"C:/KV/variable.ini\")\n","        credential = ClientSecretCredential(\n","                        client_id     =config.get(\"myvars\", \"appId\"),\n","                        client_secret =config.get(\"myvars\", \"secret\") , \n","                        tenant_id     =config.get(\"myvars\", \"tenantId\")\n","                        )\n","        token =       credential.get_token(\"https://storage.azure.com/.default\").token\n","    duckdb.sql(f\"\"\" CREATE or replace SECRET secret4 ( TYPE AZURE, PROVIDER ACCESS_TOKEN, ACCESS_TOKEN '{token}') \"\"\")\n","    ########## check if the lakehouse has a schema \n","    try:\n","        duckdb.sql(f\"\"\" SELECT  * FROM glob (\"abfss://{workspace}@onelake.dfs.fabric.microsoft.com/{LH}.Lakehouse/Tables/dbo/*\") \"\"\").df()['file'].tolist()\n","        withschema = 'yes'\n","    except:\n","        withschema = 'no'\n","    sql_schema = set()\n","    sql_statements = set()\n","    if withschema == 'yes':\n","        list_tables = duckdb.sql(f\"\"\" SELECT  distinct(split_part(file, '_delta_log', 1)) as tables FROM glob (\"abfss://{workspace}@onelake.dfs.fabric.microsoft.com/{LH}.Lakehouse/Tables/*/*/_delta_log/00000000000000000000.json\") \"\"\").df()['tables'].tolist()\n","        for table_path in list_tables:\n","            parts = table_path.strip(\"/\").split(\"/\")\n","            schema = parts[-2]\n","            table = parts[-1]\n","            sql_schema.add(f\"CREATE SCHEMA IF NOT EXISTS {schema};\")\n","            sql_statements.add(f\"\"\"CREATE OR REPLACE VIEW {schema}.{table} AS SELECT * \n","                                FROM delta_scan('abfss://{workspace}@onelake.dfs.fabric.microsoft.com/{LH}.Lakehouse/Tables/{schema}/{table}');\"\"\")\n","        duckdb.sql(\" \".join(sql_schema))\n","    else:\n","        list_tables = duckdb.sql(f\"\"\" SELECT  distinct(split_part(file, '_delta_log', 1)) as tables FROM glob (\"abfss://{workspace}@onelake.dfs.fabric.microsoft.com/{LH}.Lakehouse/Tables/*/_delta_log/00000000000000000000.json\") \"\"\").df()['tables'].tolist()\n","        for table_path in list_tables:\n","            parts = table_path.strip(\"/\").split(\"/\")\n","            table = parts[-1]\n","            sql_statements.add(f\"\"\"CREATE OR REPLACE VIEW {table} AS SELECT * \n","                                FROM delta_scan('abfss://{workspace}@onelake.dfs.fabric.microsoft.com/{LH}.Lakehouse/Tables/{table}');\"\"\")\n","    duckdb.sql(\" \".join(sql_statements))\n","    duckdb.sql(\"SHOW ALL TABLES\").show(max_width=100)\n","attach_lakehouse(\"sqlengines\",\"ETL\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"f7f4343b-4407-4443-8479-de0b827c2d23","normalized_state":"finished","queued_time":"2024-10-26T05:33:45.5253926Z","session_start_time":null,"execution_start_time":"2024-10-26T05:33:46.1221086Z","execution_finish_time":"2024-10-26T05:33:52.7993022Z","parent_msg_id":"559e3627-2100-4d60-a157-54794433f89d"},"text/plain":"StatementMeta(, f7f4343b-4407-4443-8479-de0b827c2d23, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["┌──────────┬─────────┬──────────────────┬──────────────────────┬───────────────────────┬───────────┐\n│ database │ schema  │       name       │     column_names     │     column_types      │ temporary │\n│ varchar  │ varchar │     varchar      │      varchar[]       │       varchar[]       │  boolean  │\n├──────────┼─────────┼──────────────────┼──────────────────────┼───────────────────────┼───────────┤\n│ memory   │ T1      │ chdb             │ [UNIT, VERSION, SE…  │ [VARCHAR, DOUBLE, I…  │ false     │\n│ memory   │ T1      │ duckdb           │ [UNIT, DUID, filen…  │ [VARCHAR, VARCHAR, …  │ false     │\n│ memory   │ T1      │ duckdbparquet    │ [UNIT, DUID, filen…  │ [VARCHAR, VARCHAR, …  │ false     │\n│ memory   │ T1      │ pandas           │ [UNIT, version, SE…  │ [VARCHAR, BIGINT, T…  │ false     │\n│ memory   │ T1      │ pyarrow          │ [year, UNIT, VERSI…  │ [BIGINT, VARCHAR, D…  │ false     │\n│ memory   │ T10     │ duckdb           │ [UNIT, DUID, filen…  │ [VARCHAR, VARCHAR, …  │ false     │\n│ memory   │ T2      │ chdb             │ [UNIT, VERSION, SE…  │ [VARCHAR, DOUBLE, I…  │ false     │\n│ memory   │ T2      │ duckdb           │ [UNIT, DUID, filen…  │ [VARCHAR, VARCHAR, …  │ false     │\n│ memory   │ T2      │ pandas           │ [UNIT, version, SE…  │ [VARCHAR, BIGINT, T…  │ false     │\n│ memory   │ T2300   │ daft             │ [UNIT, VERSION, SE…  │ [VARCHAR, DOUBLE, T…  │ false     │\n│   ·      │  ·      │  ·               │          ·           │           ·           │   ·       │\n│   ·      │  ·      │  ·               │          ·           │           ·           │   ·       │\n│   ·      │  ·      │  ·               │          ·           │           ·           │   ·       │\n│ memory   │ T60     │ duckdbparquet    │ [UNIT, DUID, filen…  │ [VARCHAR, VARCHAR, …  │ false     │\n│ memory   │ T60     │ ibis             │ [UNIT, VERSION, SE…  │ [VARCHAR, DOUBLE, T…  │ false     │\n│ memory   │ T60     │ polars           │ [UNIT, VERSION, SE…  │ [VARCHAR, DOUBLE, T…  │ false     │\n│ memory   │ T60     │ pyarrow          │ [year, UNIT, VERSI…  │ [BIGINT, VARCHAR, D…  │ false     │\n│ memory   │ T60     │ spark            │ [UNIT, VERSION, SE…  │ [VARCHAR, DOUBLE, T…  │ false     │\n│ memory   │ T60     │ sparkdistributed │ [UNIT, VERSION, SE…  │ [VARCHAR, DOUBLE, T…  │ false     │\n│ memory   │ T60     │ sparkzstd        │ [UNIT, VERSION, SE…  │ [VARCHAR, DOUBLE, T…  │ false     │\n│ memory   │ T60     │ sqlframe         │ [unit, version, se…  │ [VARCHAR, DOUBLE, T…  │ false     │\n│ memory   │ TT      │ duckdb           │ [UNIT, DUID, filen…  │ [VARCHAR, VARCHAR, …  │ false     │\n│ memory   │ dbo     │ xx_deltastats    │ [tbl, file_name, n…  │ [VARCHAR, VARCHAR, …  │ false     │\n├──────────┴─────────┴──────────────────┴──────────────────────┴───────────────────────┴───────────┤\n│ 29 rows (20 shown)                                                                     6 columns │\n└──────────────────────────────────────────────────────────────────────────────────────────────────┘\n\n"]}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"6caff40b-ca1a-40f9-835c-75bdc7e74f1b"}],"metadata":{"colab":{"collapsed_sections":["SF7CWQywYcnY"],"provenance":[]},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"notebook_environment":{},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"state":{},"version":"0.1"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"},"enableDebugMode":false}},"dependencies":{"environment":{},"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}