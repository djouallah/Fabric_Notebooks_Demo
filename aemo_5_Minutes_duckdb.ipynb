{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install deltalake\n",
        "#!pip install duckdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9Akv_m-Zc_j",
        "outputId": "4623bdb1-aecb-4deb-f363-a1237ad98e2a"
      },
      "id": "w9Akv_m-Zc_j",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deltalake in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.10/dist-packages (from deltalake) (17.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=16->deltalake) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Nbr_Files_to_Download   = 280\n",
        "schema                  = 'aemo'\n",
        "summary_table           = 'summary'\n",
        "storage_options         = {\"allow_unsafe_rename\":\"true\"}"
      ],
      "outputs": [],
      "execution_count": 77,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "b4fdcaf1-09c8-45b0-a7f9-34ba0422f130",
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        }
      },
      "id": "b4fdcaf1-09c8-45b0-a7f9-34ba0422f130"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<mark>Import</mark>**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "7be68e54-8095-4c47-9b29-cc3ea77c1ed7"
      },
      "id": "7be68e54-8095-4c47-9b29-cc3ea77c1ed7"
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pyarrow as pa\n",
        "import pyarrow.compute as pc\n",
        "import os\n",
        "from   deltalake import DeltaTable\n",
        "from   deltalake.writer import write_deltalake, try_get_deltatable\n",
        "import glob\n",
        "import re\n",
        "import requests\n",
        "from   shutil import unpack_archive\n",
        "from   urllib.request import urlopen\n",
        "import multiprocessing"
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "e8eb4b30-4605-4e87-b259-cf535b6e22f6",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "e8eb4b30-4605-4e87-b259-cf535b6e22f6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<mark>Download Some Data from the web</mark>**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "ee4d52d4-761a-4e7b-993b-0889fda74a94"
      },
      "id": "ee4d52d4-761a-4e7b-993b-0889fda74a94"
    },
    {
      "cell_type": "code",
      "source": [
        "def download(url,Path,Onelake_table,total_files):\n",
        "    if not os.path.exists(Path):\n",
        "      os.makedirs(Path, exist_ok=True)\n",
        "    result = urlopen(url).read().decode('utf-8')\n",
        "    pattern = re.compile(r'[\\w.]*.zip')\n",
        "    filelist1 = pattern.findall(result)\n",
        "    filelist_unique = dict.fromkeys(filelist1)\n",
        "    filelist =sorted(filelist_unique)\n",
        "    dt =try_get_deltatable(Onelake_table,storage_options=storage_options)\n",
        "    if dt is not None:\n",
        "     existing_files = dt.to_pandas(columns=[\"file\"])['file'].unique().tolist()\n",
        "     existing_files = [w.replace('.CSV','.zip') for w in existing_files]\n",
        "    else:\n",
        "     existing_files =[]\n",
        "    files_to_upload = list(set(filelist) - set(existing_files))\n",
        "    files_to_upload = sorted(list(dict.fromkeys(files_to_upload)))[:total_files]\n",
        "    print(str(len(files_to_upload)) + ' New File Downloaded')\n",
        "    if len(files_to_upload) != 0 :\n",
        "      for x in files_to_upload:\n",
        "           with requests.get(url+x, stream=True) as resp:\n",
        "            if resp.ok:\n",
        "              with open(f\"{Path}{x}\", \"wb\") as f:\n",
        "               for chunk in resp.iter_content(chunk_size=4096):\n",
        "                f.write(chunk)\n",
        "    return files_to_upload"
      ],
      "outputs": [],
      "execution_count": 80,
      "metadata": {
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "28416977-0f39-41ca-aa84-9a5d42a6e519",
        "cellView": "form",
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        }
      },
      "id": "28416977-0f39-41ca-aa84-9a5d42a6e519"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<mark>Unzip</mark>**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "4d20ed8d-8b3f-462b-a866-8736eab45789"
      },
      "id": "4d20ed8d-8b3f-462b-a866-8736eab45789"
    },
    {
      "cell_type": "code",
      "source": [
        "def uncompress(x):\n",
        "        unpack_archive(str(Zip_Path+x), str(Csv_Path), 'zip')\n",
        "def unzip(Source, Destination,files_to_upload):\n",
        "    if not os.path.exists(Destination):\n",
        "      os.makedirs(Destination, exist_ok=True)\n",
        "    print(str(len(files_to_upload)) + ' New File uncompressed')\n",
        "    if len(files_to_upload) != 0 :\n",
        "      with multiprocessing.Pool() as pool:\n",
        "       for _ in pool.imap_unordered(uncompress, files_to_upload, chunksize=1):\n",
        "         pass\n",
        "      return [Csv_Path + i for i in files_to_upload]\n",
        "    else:\n",
        "     return []"
      ],
      "outputs": [],
      "execution_count": 81,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "cellView": "form",
        "id": "3b5f3047-8010-41ba-8e30-396e26de0e81",
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        }
      },
      "id": "3b5f3047-8010-41ba-8e30-396e26de0e81"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<mark>Price Today </mark>**"
      ],
      "metadata": {
        "id": "HPeQ0W-DtsEI"
      },
      "id": "HPeQ0W-DtsEI"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_price(files_to_upload_full_Path):\n",
        "  raw =duckdb.sql(f\"\"\"from read_csv({files_to_upload_full_Path},\n",
        "  Skip=1,header =0,all_varchar=1,\n",
        "  columns={{\n",
        "  'I' : 'VARCHAR', 'DISPATCH' : 'VARCHAR', 'PRICE' : 'VARCHAR', 'xx' : 'VARCHAR', 'SETTLEMENTDATE' : 'VARCHAR', 'RUNNO' : 'VARCHAR', 'REGIONID' : 'VARCHAR',\n",
        "   'DISPATCHINTERVAL' : 'VARCHAR', 'INTERVENTION' : 'VARCHAR', 'RRP' : 'VARCHAR', 'EEP' : 'VARCHAR', 'ROP' : 'VARCHAR', 'APCFLAG' : 'VARCHAR',\n",
        "    'MARKETSUSPENDEDFLAG' : 'VARCHAR', 'LASTCHANGED' : 'VARCHAR', 'RAISE6SECRRP' : 'VARCHAR', 'RAISE6SECROP' : 'VARCHAR', 'RAISE6SECAPCFLAG' : 'VARCHAR',\n",
        "    'RAISE60SECRRP' : 'VARCHAR', 'RAISE60SECROP' : 'VARCHAR', 'RAISE60SECAPCFLAG' : 'VARCHAR', 'RAISE5MINRRP' : 'VARCHAR', 'RAISE5MINROP' : 'VARCHAR',\n",
        "    'RAISE5MINAPCFLAG' : 'VARCHAR', 'RAISEREGRRP' : 'VARCHAR', 'RAISEREGROP' : 'VARCHAR', 'RAISEREGAPCFLAG' : 'VARCHAR', 'LOWER6SECRRP' : 'VARCHAR',\n",
        "     'LOWER6SECROP' : 'VARCHAR', 'LOWER6SECAPCFLAG' : 'VARCHAR', 'LOWER60SECRRP' : 'VARCHAR', 'LOWER60SECROP' : 'VARCHAR', 'LOWER60SECAPCFLAG' : 'VARCHAR',\n",
        "     'LOWER5MINRRP' : 'VARCHAR', 'LOWER5MINROP' : 'VARCHAR', 'LOWER5MINAPCFLAG' : 'VARCHAR', 'LOWERREGRRP' : 'VARCHAR', 'LOWERREGROP' : 'VARCHAR',\n",
        "      'LOWERREGAPCFLAG' : 'VARCHAR', 'PRICE_STATUS' : 'VARCHAR', 'PRE_AP_ENERGY_PRICE' : 'VARCHAR', 'PRE_AP_RAISE6_PRICE' : 'VARCHAR', 'PRE_AP_RAISE60_PRICE' : 'VARCHAR',\n",
        "       'PRE_AP_RAISE5MIN_PRICE' : 'VARCHAR', 'PRE_AP_RAISEREG_PRICE' : 'VARCHAR', 'PRE_AP_LOWER6_PRICE' : 'VARCHAR', 'PRE_AP_LOWER60_PRICE' : 'VARCHAR',\n",
        "        'PRE_AP_LOWER5MIN_PRICE' : 'VARCHAR', 'PRE_AP_LOWERREG_PRICE' : 'VARCHAR', 'RAISE1SECRRP' : 'VARCHAR', 'RAISE1SECROP' : 'VARCHAR', 'RAISE1SECAPCFLAG' : 'VARCHAR',\n",
        "         'LOWER1SECRRP' : 'VARCHAR', 'LOWER1SECROP' : 'VARCHAR', 'LOWER1SECAPCFLAG' : 'VARCHAR', 'PRE_AP_RAISE1_PRICE' : 'VARCHAR',\n",
        "          'PRE_AP_LOWER1_PRICE' : 'VARCHAR', 'CUMUL_PRE_AP_ENERGY_PRICE' : 'VARCHAR', 'CUMUL_PRE_AP_RAISE6_PRICE' : 'VARCHAR', 'CUMUL_PRE_AP_RAISE60_PRICE' : 'VARCHAR',\n",
        "          'CUMUL_PRE_AP_RAISE5MIN_PRICE' : 'VARCHAR', 'CUMUL_PRE_AP_RAISEREG_PRICE' : 'VARCHAR', 'CUMUL_PRE_AP_LOWER6_PRICE' : 'VARCHAR',\n",
        "          'CUMUL_PRE_AP_LOWER60_PRICE' : 'VARCHAR', 'CUMUL_PRE_AP_LOWER5MIN_PRICE' : 'VARCHAR', 'CUMUL_PRE_AP_LOWERREG_PRICE' : 'VARCHAR',\n",
        "          'CUMUL_PRE_AP_RAISE1_PRICE' : 'VARCHAR', 'CUMUL_PRE_AP_LOWER1_PRICE' : 'VARCHAR', 'OCD_STATUS' : 'VARCHAR', 'MII_STATUS' : 'VARCHAR',\n",
        "  }},\n",
        "  filename =1,null_padding = true,ignore_errors=1,auto_detect=false)\n",
        "  where I='D' and PRICE ='PRICE'\n",
        "\n",
        "                  \"\"\")\n",
        "  columns = list(set(raw.columns) - {'SETTLEMENTDATE','REGIONID','I','PRICE','filename','OCD_STATUS','MII_STATUS','DISPATCH','PRICE_STATUS','LASTCHANGED'})\n",
        "\n",
        "  exprs = [\n",
        "    duckdb.ColumnExpression(x).cast(duckdb.typing.DOUBLE).alias(x)\n",
        "    for x in columns\n",
        "  ]\n",
        "  rel2 = raw.select('SETTLEMENTDATE','REGIONID','I','PRICE','filename','OCD_STATUS','MII_STATUS','DISPATCH','PRICE_STATUS','LASTCHANGED',*exprs)\n",
        "  final=duckdb.sql(\"\"\" select *exclude(SETTLEMENTDATE,I,xx,'PRICE','filename'),\n",
        "  cast (SETTLEMENTDATE as TIMESTAMPTZ) as SETTLEMENTDATE,\n",
        "  cast(SETTLEMENTDATE as date) as date,\n",
        "  parse_filename(filename) as file,\n",
        "  0 as PRIORITY,\n",
        "  isoyear (cast (SETTLEMENTDATE as TIMESTAMPTZ)) as YEAR\n",
        "  from rel2  \"\"\")\n",
        "  return final.arrow()"
      ],
      "outputs": [],
      "execution_count": 82,
      "metadata": {
        "id": "BhdYGAod4Vid",
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "jupyter": {
          "source_hidden": true
        }
      },
      "id": "BhdYGAod4Vid"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<mark>SCADA Today </mark>**"
      ],
      "metadata": {
        "id": "Gg9hRwlEVjGM"
      },
      "id": "Gg9hRwlEVjGM"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def get_scada(files_to_upload_full_Path):\n",
        "  raw =duckdb.sql(f\"\"\"from read_csv({files_to_upload_full_Path},\n",
        "  Skip=1,header =0,all_varchar=1,\n",
        "  columns={{\n",
        "  'I' : 'VARCHAR', 'DISPATCH' : 'VARCHAR', 'UNIT_SCADA' : 'VARCHAR', 'xx' : 'VARCHAR', 'SETTLEMENTDATE' : 'timestamp', 'DUID' : 'VARCHAR', 'SCADAVALUE' : 'double','LASTCHANGED' : 'timestamp'\n",
        "  }},\n",
        "  filename =1,null_padding = true,ignore_errors=1,auto_detect=false)\n",
        "  where I='D' and SCADAVALUE !=0\n",
        "                  \"\"\")\n",
        "  scada=duckdb.sql(\"\"\" select  DUID,SCADAVALUE as INITIALMW, cast(0 as double ) as INTERVENTION,\n",
        "   cast (SETTLEMENTDATE as TIMESTAMPTZ) as SETTLEMENTDATE,\n",
        "   cast(SETTLEMENTDATE as date) as date,\n",
        "   parse_filename(filename) as file,\n",
        "   0 as PRIORITY ,\n",
        "   isoyear (cast (SETTLEMENTDATE as timestamp)) as YEAR\n",
        "   from raw\n",
        "    \"\"\")\n",
        "  return scada.arrow()"
      ],
      "outputs": [],
      "execution_count": 83,
      "metadata": {
        "id": "U_XTWvrrWByo",
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "jupyter": {
          "source_hidden": true
        }
      },
      "id": "U_XTWvrrWByo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<mark>DUID </mark>**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "c91da29f-926f-47db-aba4-bfcb3788dbc6"
      },
      "id": "c91da29f-926f-47db-aba4-bfcb3788dbc6"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_duid(Onelake_table,storage_options):\n",
        "    DUID_Path = \"/lakehouse/default/Files/0_Source/Dimensions/DUID/\"\n",
        "    import pathlib\n",
        "    import requests\n",
        "    pathlib.Path(DUID_Path).mkdir(parents=True, exist_ok=True)\n",
        "    url = \"https://www.aemo.com.au/-/media/Files/Electricity/NEM/Participant_Information/NEM-Registration-and-Exemption-List.xls\"\n",
        "    s = requests.Session()\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'}\n",
        "    r = s.get(url,headers=headers)\n",
        "    r.content\n",
        "    output = open(DUID_Path+\"NEM-Registration-and-Exemption-List.xls\", 'wb')\n",
        "    output.write(r.content)\n",
        "    output.close()\n",
        "    duckdb.sql(f\"\"\"\n",
        "    INSTALL spatial;\n",
        "    LOAD spatial;\n",
        "    create or replace table DUID as\n",
        "    SELECT Region,DUID,first(\"Fuel Source - Descriptor\") as FuelSourceDescriptor,first(Participant) as Participant\n",
        "    FROM st_read('{DUID_Path}NEM-Registration-and-Exemption-List.xls', layer = 'PU and Scheduled Loads',open_options = ['HEADERS=FORCE'])\n",
        "    group by all\n",
        "    \"\"\")\n",
        "\n",
        "    import requests\n",
        "    dls = \"https://data.wa.aemo.com.au/datafiles/post-facilities/facilities.csv\"\n",
        "    resp = requests.get(dls)\n",
        "    output = open(DUID_Path+\"facilities_WA.csv\", 'wb')\n",
        "    output.write(resp.content)\n",
        "    output.close()\n",
        "\n",
        "    duckdb.sql(f\"\"\" select 'WA1' as Region  , \"Facility Code\" as DUID ,\"Participant Name\" as Participant from read_csv_auto('{DUID_Path}facilities_WA.csv')\"\"\").to_view('x')\n",
        "\n",
        "    duckdb.sql(\"\"\"select x.Region,x.DUID, TECHNOLOGY as FuelSourceDescriptor,Participant from x\n",
        "    left join (select * FROM read_csv_auto('https://github.com/djouallah/aemo_fabric/raw/main/WA_ENERGY.csv',header=1)) as z\n",
        "    on x.duid=z.duid \"\"\").to_view('DUID_WA')\n",
        "\n",
        "    duckdb.sql(\"\"\"\n",
        "    create or replace table states(RegionID varchar, States varchar) ;\n",
        "    insert into states values\n",
        "    ('WA1' , 'Western Australia') ,\n",
        "    ('QLD1' , 'Queensland')  ,\n",
        "    ('NSW1' , 'New South Walles')  ,\n",
        "    ('TAS1' , 'Tasmania')  ,\n",
        "    ('SA1' , 'South Australia')  ,\n",
        "    ('VIC1' , 'Victoria')\n",
        "    \"\"\")\n",
        "\n",
        "    df =duckdb.sql(f\"\"\" with xx as (select * from DUID union BY NAME select * from DUID_WA)\n",
        "                select States,trim(DUID) as DUID,min(Region) as Region, min(FuelSourceDescriptor) as FuelSourceDescriptor,\n",
        "                min(Participant) as Participant\n",
        "                from xx\n",
        "                JOIN states on xx.Region = states.RegionID\n",
        "                group by all\n",
        "                \"\"\").arrow()\n",
        "    write_deltalake(Onelake_table, df,mode=\"overwrite\",engine='rust',storage_options = storage_options)"
      ],
      "outputs": [],
      "execution_count": 84,
      "metadata": {
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "aae61997-f447-4096-8d8d-cfcfd2c81746"
      },
      "id": "aae61997-f447-4096-8d8d-cfcfd2c81746"
    },
    {
      "cell_type": "markdown",
      "source": [
        "_**<mark>Summary</mark>**_"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "be6d663c-4389-411c-8414-359c1ea7aceb"
      },
      "id": "be6d663c-4389-411c-8414-359c1ea7aceb"
    },
    {
      "cell_type": "code",
      "source": [
        "sch = pa.schema([(\"settlementdate\", pa.timestamp(\"us\",\"UTC\")),\n",
        "                    (\"date\", pa.date32()),\n",
        "                    (\"DUID\", pa.string()),\n",
        "                    (\"States\", pa.string()),\n",
        "                    (\"mw\", pa.float64()),\n",
        "                    (\"price\", pa.float64()),\n",
        "         ])\n",
        "DeltaTable.create(f'/lakehouse/default/Tables/{schema}/{summary_table}', schema=sch,mode=\"ignore\",storage_options = storage_options)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaTable()"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "execution_count": 85,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "734f8523-5669-4142-b749-631b484962b6",
        "outputId": "0e0c9633-278e-47da-ea18-4a29ebb210d1"
      },
      "id": "734f8523-5669-4142-b749-631b484962b6"
    },
    {
      "cell_type": "code",
      "source": [
        "sch = pa.schema([(\"table\", pa.string()),(\"version\", pa.int64())])\n",
        "DeltaTable.create(f'/lakehouse/default/Tables/{schema}/metadata', schema=sch,mode=\"ignore\",storage_options = storage_options)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaTable()"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "execution_count": 86,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4a23ced-35c0-4a35-be5b-54709e2fbef1",
        "outputId": "cc474ddf-feb9-476b-9880-9512a7fb7f78"
      },
      "id": "d4a23ced-35c0-4a35-be5b-54709e2fbef1"
    },
    {
      "cell_type": "code",
      "source": [
        "def full_refresh(schema):\n",
        "    return f\"\"\"\n",
        "      CREATE OR REPLACE VIEW {schema}.scada AS SELECT * FROM delta_scan('/lakehouse/default/Tables/{schema}/scada');\n",
        "      CREATE OR REPLACE VIEW {schema}.price AS SELECT * FROM delta_scan('/lakehouse/default/Tables/{schema}/price');\n",
        "      select\n",
        "        cast(s.settlementdate as TIMESTAMPTZ) as settlementdate,\n",
        "        s.date,\n",
        "        s.DUID,\n",
        "        States,\n",
        "        max(s.INITIALMW) as mw,\n",
        "        max(p.RRP ) as price\n",
        "      from ( select * from  {schema}.scada  where INTERVENTION = 0 and INITIALMW <> 0)  s\n",
        "            LEFT JOIN {schema}.duid d ON s.DUID = d.DUID\n",
        "            LEFT JOIN ( select * from {schema}.price where INTERVENTION = 0)  p ON s.SETTLEMENTDATE = p.SETTLEMENTDATE AND d.Region = p.REGIONID\n",
        "      group by\n",
        "        all\n",
        "      order by s.date\n",
        "    \"\"\""
      ],
      "outputs": [],
      "execution_count": 87,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "af21959b-a306-4585-85ba-b6b5b32f2167"
      },
      "id": "af21959b-a306-4585-85ba-b6b5b32f2167"
    },
    {
      "cell_type": "code",
      "source": [
        "def Incremental_refresh(schema,max_timestamp):\n",
        "    return f\"\"\"\n",
        "      select\n",
        "        cast(s.settlementdate as TIMESTAMPTZ) as settlementdate,\n",
        "        s.date,\n",
        "        s.DUID,\n",
        "        States,\n",
        "        max(s.INITIALMW) as mw,\n",
        "        max(p.RRP ) as price\n",
        "      from\n",
        "        {schema}.scada_today  s\n",
        "        JOIN {schema}.duid d ON s.DUID = d.DUID\n",
        "        JOIN {schema}.price_today        p ON s.SETTLEMENTDATE = p.SETTLEMENTDATE AND d.Region = p.REGIONID\n",
        "      where\n",
        "        s.INTERVENTION = 0\n",
        "        and p.INTERVENTION = 0\n",
        "        and INITIALMW <> 0\n",
        "        and s.settlementdate > '{max_timestamp}' and p.settlementdate > '{max_timestamp}'\n",
        "      group by\n",
        "        all\n",
        "      order by s.date\n",
        "    \"\"\""
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "536d901f-7d72-477a-87d3-aa3b98a1f2af"
      },
      "id": "536d901f-7d72-477a-87d3-aa3b98a1f2af"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max():\n",
        "    # duckdb don't like scanning table with empty rows, fixed in 1.1.3\n",
        "    dt = DeltaTable(f'/lakehouse/default/Tables/{schema}/{summary_table}',storage_options=storage_options)\n",
        "    dataset = dt.to_pyarrow_dataset().to_table(columns=[\"settlementdate\"])\n",
        "    max_timestamp = pc.max(dataset['settlementdate']).as_py()\n",
        "    if  not max_timestamp :\n",
        "        max_timestamp = '1900-01-01'\n",
        "    else :\n",
        "        max_timestamp =  max_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    return max_timestamp"
      ],
      "outputs": [],
      "execution_count": 89,
      "metadata": {
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "27a393a5-1009-48a4-9697-70320fd12fdb"
      },
      "id": "27a393a5-1009-48a4-9697-70320fd12fdb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Data"
      ],
      "metadata": {
        "id": "XRr_LskEkj9k"
      },
      "id": "XRr_LskEkj9k"
    },
    {
      "cell_type": "code",
      "source": [
        "Web_Path          = \"http://nemweb.com.au/Reports/Current/DispatchIS_Reports/\"\n",
        "Zip_Path          = \"/lakehouse/default/Files/0_Source/Current/DispatchIS_Reports/\"\n",
        "Csv_Path          =  \"/tmp/\"\n",
        "Onelake_table     = '/lakehouse/default/Tables/'+schema+'/price_today'\n",
        "\n",
        "files_to_upload = download(Web_Path,Zip_Path,Onelake_table,Nbr_Files_to_Download)\n",
        "files_to_upload_full_Path_zip=unzip(Zip_Path,Csv_Path,files_to_upload)\n",
        "files_to_upload_full_Path = [w.replace('.zip','.CSV') for w in files_to_upload_full_Path_zip]\n",
        "\n",
        "if len(files_to_upload_full_Path) >0 :\n",
        "  df = get_price(files_to_upload_full_Path)\n",
        "  write_deltalake(Onelake_table, df,mode=\"append\",partition_by=['date'],engine='rust',storage_options=storage_options)\n",
        "else:\n",
        "  print('all loaded already')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 New File Downloaded\n",
            "0 New File uncompressed\n",
            "all loaded already\n"
          ]
        }
      ],
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "id": "f6536736-55ec-4af9-a603-17a4e779af7a",
        "outputId": "0cfe8dd9-003d-42be-9ffe-e4a38ae72798",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "f6536736-55ec-4af9-a603-17a4e779af7a"
    },
    {
      "cell_type": "code",
      "source": [
        "Web_Path          = \"http://nemweb.com.au/Reports/Current/Dispatch_SCADA/\"\n",
        "Zip_Path          = \"/lakehouse/default/Files/0_Source/Current/Dispatch_SCADA/\"\n",
        "Csv_Path          =  \"/tmp/scada/\"\n",
        "Onelake_table     = '/lakehouse/default/Tables/'+schema+'/scada_today'\n",
        "\n",
        "files_to_upload = download(Web_Path,Zip_Path,Onelake_table,Nbr_Files_to_Download)\n",
        "files_to_upload_full_Path_zip=unzip(Zip_Path,Csv_Path,files_to_upload)\n",
        "files_to_upload_full_Path = [w.replace('.zip','.CSV') for w in files_to_upload_full_Path_zip]\n",
        "if len(files_to_upload_full_Path) >0 :\n",
        "  df = get_scada(files_to_upload_full_Path)\n",
        "  write_deltalake(Onelake_table, df,mode=\"append\",partition_by=['date'],engine='rust',storage_options=storage_options)\n",
        "else:\n",
        "  print('all loaded already')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 New File Downloaded\n",
            "0 New File uncompressed\n",
            "all loaded already\n"
          ]
        }
      ],
      "execution_count": 91,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf0cd460-29dc-48f7-8634-71b0a9ef06cf",
        "outputId": "32a0bbea-c15b-4f22-aa48-22e7d5831948"
      },
      "id": "cf0cd460-29dc-48f7-8634-71b0a9ef06cf"
    },
    {
      "cell_type": "code",
      "source": [
        "Onelake_table = f'/lakehouse/default/Tables/{schema}/duid'\n",
        "dt =try_get_deltatable(Onelake_table,storage_options=storage_options)\n",
        "if dt is None:\n",
        "    get_duid(Onelake_table,storage_options)\n",
        "else:\n",
        "    print('duid loaded already')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duid loaded already\n"
          ]
        }
      ],
      "execution_count": 92,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4530b7d6-4118-4ca7-9e40-3facd2f444e8",
        "outputId": "e5b2dea5-47c5-4931-d733-d28d838052ff"
      },
      "id": "4530b7d6-4118-4ca7-9e40-3facd2f444e8"
    },
    {
      "cell_type": "code",
      "source": [
        "Onelake_table = f'/lakehouse/default/Tables/{schema}/mstdatetime'\n",
        "dt =try_get_deltatable(Onelake_table,storage_options=storage_options)\n",
        "if dt is None:\n",
        "    df=duckdb.sql(\"\"\" SELECT cast(unnest(generate_series(cast ('2018-04-01' as date), cast('2024-12-31' as date), interval 5 minute)) as TIMESTAMPTZ) as SETTLEMENTDATE,\n",
        "            strftime(SETTLEMENTDATE, '%I:%M:%S %p') as time,\n",
        "            cast(SETTLEMENTDATE as date ) as date,\n",
        "            EXTRACT(year from date) as year,\n",
        "            EXTRACT(month from date) as month\n",
        "            \"\"\").arrow()\n",
        "    write_deltalake(Onelake_table, df,mode=\"ignore\",storage_options = storage_options,engine='rust')\n",
        "else:\n",
        "    print('mstdatetime loaded already')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mstdatetime loaded already\n"
          ]
        }
      ],
      "execution_count": 93,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fafd822-a9bf-4e05-af90-c8738488dcc3",
        "outputId": "824ec33c-6cec-428e-f5fb-53fe289d2229"
      },
      "id": "5fafd822-a9bf-4e05-af90-c8738488dcc3"
    },
    {
      "cell_type": "code",
      "source": [
        "Onelake_table = f'/lakehouse/default/Tables/{schema}/calendar'\n",
        "dt =try_get_deltatable(Onelake_table,storage_options=storage_options)\n",
        "if dt is None:\n",
        "    df=duckdb.sql(\"\"\" SELECT cast(unnest(generate_series(cast ('2018-04-01' as date), cast('2024-12-31' as date), interval 1 day)) as date) as date,\n",
        "            EXTRACT(year from date) as year,\n",
        "            EXTRACT(month from date) as month\n",
        "            \"\"\").arrow()\n",
        "    write_deltalake(Onelake_table, df,mode=\"ignore\",storage_options = storage_options,engine='rust')\n",
        "else:\n",
        "    print('calendar loaded already')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calendar loaded already\n"
          ]
        }
      ],
      "execution_count": 94,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e31a5a9f-3b79-45e0-9354-d9d495ea95b2",
        "outputId": "34b45138-51ce-490e-ab51-b06afa715878"
      },
      "id": "e31a5a9f-3b79-45e0-9354-d9d495ea95b2"
    },
    {
      "cell_type": "code",
      "source": [
        "#### check if scada was updated\n",
        "duckdb.sql(f\"create SCHEMA IF NOT EXISTS {schema}\")\n",
        "for tbl in ['scada_today','duid','price_today',summary_table]:\n",
        "    duckdb.sql(f\"CREATE OR REPLACE VIEW {schema}.{tbl} AS SELECT * FROM delta_scan('/lakehouse/default/Tables/{schema}/{tbl}');\")\n",
        "dt = try_get_deltatable(f'/lakehouse/default/Tables/{schema}/scada',storage_options=storage_options)\n",
        "if dt is None:\n",
        " current_version = -1\n",
        "else:\n",
        " current_version = dt.version()\n",
        "Previous_version = duckdb.sql(f\"SELECT max(version) FROM delta_scan('/lakehouse/default/Tables/{schema}/metadata');\").fetchone()[0]\n",
        "Previous_version = Previous_version or 0\n",
        "print(f'scada current  version {current_version}')\n",
        "print(f'scada previous version {Previous_version}')\n",
        "if current_version != Previous_version and current_version !=-1:\n",
        "    print('scada table was updated, trigger full refresh')\n",
        "    get_duid(f'/lakehouse/default/Tables/{schema}/duid',storage_options)\n",
        "    df = duckdb.sql(full_refresh(schema)).arrow()\n",
        "    r = df.num_rows\n",
        "    if r >0 :\n",
        "        RG=8_000_000\n",
        "        write_deltalake('/lakehouse/default/Tables/'+schema+\"/\"+summary_table,\n",
        "                         df,\n",
        "                         mode=\"overwrite\",\n",
        "                         max_rows_per_group = RG,\n",
        "                         min_rows_per_group = RG,\n",
        "                         storage_options= storage_options,\n",
        "                         engine='rust')\n",
        "        print('store new version')\n",
        "        df = pa.table({'table': ['scada'], 'version': [current_version]})\n",
        "        write_deltalake(f'/lakehouse/default/Tables/{schema}/metadata', df,mode=\"overwrite\",engine='rust',storage_options = storage_options)\n",
        "else:\n",
        "    print('scada table was not updated, trigger incremental refresh')\n",
        "    max_timestamp = get_max()\n",
        "    df = duckdb.sql(Incremental_refresh(schema,max_timestamp)).arrow()\n",
        "    r = df.num_rows\n",
        "    if r >0 :\n",
        "        write_deltalake('/lakehouse/default/Tables/'+schema+\"/\"+summary_table, df, mode=\"append\", storage_options= storage_options, engine='rust')\n",
        "        print(f'new {r} rows inserted')\n",
        "    else :\n",
        "        print(\"no new data\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scada current  version -1\n",
            "scada previous version 0\n",
            "scada table was not updated, trigger incremental refresh\n",
            "no new data\n"
          ]
        }
      ],
      "execution_count": 95,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python",
          "language_group": "jupyter_python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678dc3b0-1d0b-45a3-afce-91d08dadbb69",
        "outputId": "d1533956-2497-43fe-aed0-ef7342573321"
      },
      "id": "678dc3b0-1d0b-45a3-afce-91d08dadbb69"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "microsoft": {
      "language": "python",
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "language_group": "jupyter_python"
    },
    "notebook_environment": {},
    "sessionKeepAliveTimeout": 0,
    "kernel_info": {
      "name": "jupyter",
      "jupyter_kernel_name": "python3.11"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "jupyter",
      "language": "Jupyter",
      "display_name": "Jupyter"
    },
    "a365ComputeOptions": null,
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    },
    "save_output": true,
    "spark_compute": {
      "compute_id": "/trident/default",
      "session_options": {
        "enableDebugMode": false,
        "conf": {
          "spark.synapse.nbs.session.timeout": "1200000"
        }
      }
    },
    "dependencies": {
      "lakehouse": {
        "default_lakehouse": "95cd7448-f098-4a3f-86e2-6fe8d08817dd",
        "default_lakehouse_name": "aemoraw",
        "default_lakehouse_workspace_id": "04f56971-b2bd-4a8f-89cf-7fc8e2513b36"
      },
      "environment": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}