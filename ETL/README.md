
# Light_ETL_Challenge


### This is just a personal project and does not represents the view of my employer.


Extract data fom a csv. the number of columns is higher than what's in the header, filter a subset of data and export to Delta Lake
I started with Duckdb , Polars ,Pandas, Pyarrow, chdb and datafusion

the script will download 60 files, around 4 GB uncompressed, you can duplicate the data, as there is no obvious way to share 150 GB of data for free

<img width="1008" height="482" alt="image" src="https://github.com/user-attachments/assets/2126f91c-1172-4e32-a87b-3bd2bb047671" />


